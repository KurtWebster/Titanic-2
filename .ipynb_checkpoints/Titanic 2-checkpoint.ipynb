{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic2_train.csv')\n",
    "test = pd.read_csv('titanic2_test.csv')\n",
    "concat = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49999.500000</td>\n",
       "      <td>0.427740</td>\n",
       "      <td>2.106910</td>\n",
       "      <td>38.355472</td>\n",
       "      <td>0.397690</td>\n",
       "      <td>0.454560</td>\n",
       "      <td>43.92933</td>\n",
       "      <td>0.38147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "      <td>0.494753</td>\n",
       "      <td>0.837727</td>\n",
       "      <td>18.009589</td>\n",
       "      <td>0.862566</td>\n",
       "      <td>0.950076</td>\n",
       "      <td>69.54218</td>\n",
       "      <td>0.48575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.68000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24999.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.04000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49999.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>38.355472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.49000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74999.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.56000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>744.66000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PassengerId       Survived         Pclass            Age  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean    49999.500000       0.427740       2.106910      38.355472   \n",
       "std     28867.657797       0.494753       0.837727      18.009589   \n",
       "min         0.000000       0.000000       1.000000       0.080000   \n",
       "25%     24999.750000       0.000000       1.000000      25.000000   \n",
       "50%     49999.500000       0.000000       2.000000      38.355472   \n",
       "75%     74999.250000       1.000000       3.000000      53.000000   \n",
       "max     99999.000000       1.000000       3.000000      87.000000   \n",
       "\n",
       "               SibSp          Parch          Fare        Family  \n",
       "count  100000.000000  100000.000000  100000.00000  100000.00000  \n",
       "mean        0.397690       0.454560      43.92933       0.38147  \n",
       "std         0.862566       0.950076      69.54218       0.48575  \n",
       "min         0.000000       0.000000       0.68000       0.00000  \n",
       "25%         0.000000       0.000000      10.04000       0.00000  \n",
       "50%         0.000000       0.000000      24.49000       0.00000  \n",
       "75%         1.000000       1.000000      33.56000       1.00000  \n",
       "max         8.000000       9.000000     744.66000       1.00000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic(df) :\n",
    "    \n",
    "    # Normalise Age\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    mms = MinMaxScaler()\n",
    "    df[['Age', 'Fare']] = mms.fit_transform(df[['Age', 'Fare']])\n",
    "    \n",
    "    # Create family categories\n",
    "    df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df['Family'].values[df['Family'].values > 0] = 1\n",
    "    \n",
    "    # Fill blanks in cabin and embarked\n",
    "    df['Cabin'] = df['Cabin'].fillna('X')\n",
    "    df['Embarked'] = df['Embarked'].fillna('X')\n",
    "    \n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    df[['Age', 'Fare']] = imp.fit_transform(df[['Age', 'Fare']])\n",
    "\n",
    "    #Create decks\n",
    "    df['Deck'] = df['Cabin'].str[:1]\n",
    "    \n",
    "    # Select columns\n",
    "    amend = ['Pclass','Sex','Embarked','Age','Family','Deck']\n",
    "    df_amend = df[amend]\n",
    "    \n",
    "    # Get dummies\n",
    "    dummy = pd.get_dummies(df_amend, drop_first=True)\n",
    "    \n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic(train)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{LinearRegression(): 0.32552686719737933,\n",
       " LogisticRegression(max_iter=200): 0.7671,\n",
       " DecisionTreeClassifier(): 0.7536666666666667,\n",
       " RandomForestClassifier(): 0.7568666666666667}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "tree = DecisionTreeClassifier()\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "models = [lin_reg, log_reg, tree, forest]\n",
    "accuracy = []\n",
    "\n",
    "for model in models :\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy.append(model.score(X_test, y_test))\n",
    "    \n",
    "results_zip = zip(models, accuracy)\n",
    "results = dict(results_zip)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7695"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=200, penalty='none')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kurtw\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77318\n",
      "{'penalty': 'none'}\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=200)\n",
    "\n",
    "params = {'penalty' : ['l1', 'l2', 'elasticnet', 'none']}\n",
    "\n",
    "log_reg_cv = GridSearchCV(log_reg, params, cv=5)\n",
    "log_reg_cv.fit(X, y)\n",
    "\n",
    "print(log_reg_cv.best_score_)\n",
    "print(log_reg_cv.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
